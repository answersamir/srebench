You are an expert system designed to generate synthetic incident scenarios for an AIOps benchmark called SREBench using available tools. Your task is to create a realistic-looking, albeit simplified for this Proof of Concept (POC), incident scenario for the Google Cloud Microservice Demo Kubernetes cluster and **write the output directly to files using the provided tool**.

You have access to a tool (or function) to write files. Let's conceptualize this tool call as:

```json
{
  "tool_code": "write_file",
  "parameters": {
    "filename": "<path/to/file>",
    "content": "<string_content_of_the_file>"
  }
}
Your entire response MUST consist ONLY of a sequence of these tool calls to generate and write the necessary files for a single scenario (scenario_<id>). DO NOT include any conversational text or other output before or after the tool calls.

--- SECTION 1: Incident Description and Type (Input to Agent) ---
The incident falls under the category of Resource Saturation (CPU Limit) in the Google Cloud Microservice Demo Kubernetes cluster.
Initial symptoms reported include increased user-facing latency and errors when completing orders, and potential alerts on service performance metrics for components involved in the order processing flow.

--- SECTION 2: Generate Observable State Data (Based ONLY on Section 1 Symptoms) ---
Generate the raw, observable state data that an SRE or agent would collect from monitoring and introspection tools based ONLY on the symptoms described in Section 1. Adhere to the critical constraints below.

General Constraints for State Data (CRITICAL - STRICTLY FOLLOW):

The state/ data files (logs.jsonl, metrics.json, events.jsonl, topology.json, configuration.yaml) MUST ONLY contain representations of observable symptoms and low-level operational data.
ABSOLUTELY DO NOT embed explicit statements about the root cause, diagnostic conclusions, or interpretations (e.g., "this issue is caused by...", "Insufficient CPU resources are the root cause", "Problematic configuration found", "Core issue:", "Root cause is:") anywhere within the content of the state/ data files.
The content of state/ files MUST strictly mimic the structured output format of real monitoring tools and APIs. Avoid natural language summaries or diagnostic phrasing within these data files themselves.
Generate Tool Call for description.md:

Generate the content for scenario_<id>/description.md. It should be a natural language description of the symptoms an SRE or monitoring system would initially observe. Focus on user experience issues (slow checkouts, payment errors) and service-level symptoms (high latency, errors in relevant services like checkoutservice calling paymentservice), consistent with a resource issue impacting a core service.
Make a write_file tool call with filename: "scenario_<id>/description.md" and the generated description as content.
Generate Tool Call for state/logs.jsonl:

Generate the content for scenario_<id>/state/logs.jsonl. A few sample log entries (5-10 total) across the involved services (paymentservice, checkoutservice, cartservice). Include typical timestamps (RFC3339), service/pod names, levels (info, warning, error), and messages that reflect the observed state. Ensure log messages themselves are purely observational and do not state the root cause or diagnostics. Format as newline-delimited JSON.
Make a write_file tool call with filename: "scenario_<id>/state/logs.jsonl" and the generated log content as content.
Generate Tool Call for state/metrics.json:

Generate the content for scenario_<id>/state/metrics.json as a JSON object representing key metric time-series data points observed during the incident window. Mimic the structure of time-series data retrieved from monitoring APIs. Follow this exact structure:
JSON

{
  "metrics": [
    {
      "name": "string", // e.g., "kubernetes_io/container/cpu/utilization_rate", "opencensus_io/http/server/latency"
      "unit": "string", // e.g., "cores", "ms", "By", "count", "ns"
      "resource": { // Resource the metric is associated with
        "name": "string", // e.g., "paymentservice", "frontend", "node-123"
        "kind": "string", // e.g., "Deployment", "Pod", "Service", "Node"
        "namespace": "string", // e.g., "microservices-demo", "kube-system"
        "pod_name": "string" // Optional: if metric is at pod level, ensure consistency with logs/events
      },
      "labels": {}, // Optional: Key-value pairs for metric labels (e.g., {"method": "grpc.health.v1.Health/Check"})
      "data_points": [ // Representing key query results over time
        {
          "timestamp": "RFC3339 timestamp string", // Point in time
          "value": "numeric_or_string_value" // The observed value (e.g., 0.05, 0.8, "95th_percentile=0.5s")
        }
        // Include a few points showing baseline, increase, and peak/anomalous state, consistent with logs/events timing.
      ]
    }
    // ... include relevant metrics (CPU utilization, request latency, error rate) for paymentservice and dependent services.
    // Use plausible real-world metric names if known for GKE/Prometheus/opencensus.
    // DO NOT include "summary" fields or add diagnostic comments within the metric data structure.
  ]
}
Ensure consistency in component names and namespaces (e.g., paymentservice Deployment in microservices-demo namespace). Output only the JSON object content for the content parameter of the tool call.
Make a write_file tool call with filename: "scenario_<id>/state/metrics.json" and the generated metrics JSON as content.
Generate Tool Call for state/events.jsonl:

Generate the content for scenario_<id>/state/events.jsonl. Relevant Kubernetes events as newline-delimited JSON of event objects, mimicking kubectl get events -o json. Include plausible timestamps (RFC3339) and event details. Ensure event messages themselves are purely observational and do not state the root cause conclusion. For this CPU throttling scenario without crashes, this file might be empty or contain only very general events. Output only the newline-delimited JSON content.
Make a write_file tool call with filename: "scenario_<id>/state/events.jsonl" and the generated events content as content.
Generate Tool Call for state/topology.json:

Generate the content for scenario_<id>/state/topology.json. A JSON array listing the relevant services involved in this incident's propagation path and their immediate dependencies. Mimics structured output describing service relationships. Use accurate service names from the Microservice Demo. Output only the JSON array content.
Make a write_file tool call with filename: "scenario_<id>/state/topology.json" and the generated topology JSON as content.
Generate Tool Call for state/configuration.yaml:

Generate the content for scenario_<id>/state/configuration.yaml. A YAML snippet showing the relevant problematic configuration â€“ specifically, the resources section for the paymentservice container. Mimics output of kubectl get deployment paymentservice -o yaml. Crucially, DO NOT add comments to the YAML that reveal the root cause or label the config as problematic. Just show the config as retrieved. Output only the YAML snippet content.
Make a write_file tool call with filename: "scenario_<id>/state/configuration.yaml" and the generated configuration YAML as content.
--- SECTION 3: Define Specific Root Cause (Used for Ground Truth Generation) ---
The Specific Root Cause for this scenario, which explains the symptoms and state data generated in Section 2, is: a low CPU limit configured on the paymentservice deployment, set to 50m. This caused throttling under load.

--- SECTION 4: Generate Ground Truth (Based on Section 3 Root Cause & Section 2 State Data) ---
Now, generate the ground truth and metadata for this scenario, ensuring consistency with the specific root cause defined in Section 3 and supported by the state data generated in Section 2.

Generate Tool Call for ground_truth/root_cause.json:

Generate the content for scenario_<id>/ground_truth/root_cause.json as a JSON object describing the root cause. Follow this exact structure:
JSON

{
  "type": "string", // e.g., "Resource Limit", "Network Issue"
  "resource": "string", // e.g., "CPU", "Memory"
  "affected_component": {
    "name": "string", // e.g., "paymentservice", "frontend", "node-123", "redis-cart"
    "kind": "string", // e.g., "Deployment", "Pod", "Node", "Service", "Namespace", "ConfigMap"
    "namespace": "string" // e.g., "default", "microservices-demo", "kube-system"
  },
  "specific_issue": "string", // e.g., "Limit set too low", "Connectivity lost", "High usage", "Incorrect value", "Misconfiguration"
  "value": "string", // Optional: specific problematic value, e.g., "50m", "64Mi", "timeout=1s"
  "description": "string" // A brief natural language summary of the root cause for human readability
}
For this scenario (low CPU limit on paymentservice with value 50m):
JSON

{
  "type": "Resource Limit",
  "resource": "CPU",
  "affected_component": {
    "name": "paymentservice",
    "kind": "Deployment",
    "namespace": "microservices-demo"
  },
  "specific_issue": "Limit set too low",
  "value": "50m",
  "description": "The paymentservice Deployment has a CPU limit of 50m, which is insufficient under load, causing throttling."
}
Output only the JSON object content for the content parameter.
Make a write_file tool call with filename: "scenario_<id>/ground_truth/root_cause.json" and the generated root cause JSON as content.
Generate Tool Call for ground_truth/causal_graph.json:

Generate the content for scenario_<id>/ground_truth/causal_graph.json as a JSON object representing the directed causal graph of the incident. This graph shows how the root cause leads to the observed symptoms via a series of connected nodes and edges. Follow this exact structure:
JSON

{
  "nodes": [
    {
      "id": "string", // A unique short identifier for this node (e.g., "n1_rc_cpu", "n2_anomaly_cpu"). Start IDs with 'n'.
      "type": "string", // The type of state/event/anomaly (e.g., "RootCause", "ConfigState", "MetricAnomaly", "LogError", "K8sEvent", "ServiceState", "UserImpact")
      "description": "string", // A concise phrase describing this node's role in the chain (e.g., "CPU limit config", "CPU usage hits limit", "Paymentservice latency high"). Can be interpretative here as this is ground truth.
      "component": "string", // Optional: Associated component name
      "data_keys": ["string"] // Optional: List of relevant state data keys (e.g., "metrics.paymentservice.cpu_utilization"). Use keys matching the structure in state/.
    }
    // ... list of all nodes in the causal chain
  ],
  "edges": [
    {
      "source": "string", // The 'id' of the node that is the cause
      "target": "string", // The 'id' of the node that is the effect
      "type": "string" // The type of causal link (e.g., "causes", "leads_to")
    }
    // ... list of all direct causal links. Ensure edges form a valid causal path from root cause node(s) to user impact node(s).
  ]
}
Map the causal steps to nodes and edges, starting from the specific root cause defined in Section 3 and leading to the symptoms described in Section 1 and observed in the state data. Output only the JSON object content for the content parameter.
Make a write_file tool call with filename: "scenario_<id>/ground_truth/causal_graph.json" and the generated causal graph JSON as content.
Generate Tool Call for ground_truth/resolution.json:

Generate the content for scenario_<id>/ground_truth/resolution.json as a JSON object describing the primary resolution. Follow this exact structure:
JSON

{
  "action_type": "string", // e.g., "Increase Resource Limit", "Restart Component"
  "target_component": {
    "name": "string", // e.g., "paymentservice"
    "kind": "string", // e.g., "Deployment"
    "namespace": "string" // e.g., "microservices-demo"
  },
  "resource_type": "string", // Optional, e.g., "CPU", "Memory"
  "parameter_to_change": "string", // Optional, e.g., "limit", "request"
  "target_value": "string", // Optional: recommended value, e.g., "250m"
  "description": "string" // A brief natural language summary of the resolution steps for human readability
}
For this scenario (increase CPU limit):
JSON

{
  "action_type": "Increase Resource Limit",
  "target_component": {
    "name": "paymentservice",
    "kind": "Deployment",
    "namespace": "microservices-demo"
  },
  "resource_type": "CPU",
  "parameter_to_change": "limit",
  "target_value": "recommended_value_TBD", // Placeholder or suggest range like "250m-500m"
  "description": "Increase the CPU resource limit on the paymentservice Deployment to prevent throttling."
}
Output only the JSON object content for the content parameter.
Make a write_file tool call with filename: "scenario_<id>/ground_truth/resolution.json" and the generated resolution JSON as content.
Generate Tool Call for metadata.json:

Generate the content for scenario_<id>/metadata.json as a JSON object containing basic metadata like incident_type: "Resource Saturation", root_cause_type: "CPU Limit", affected_services: ["paymentservice", "checkoutservice", "cartservice", "frontend"], scenario_id: "scenario_<id>", cluster_env: "Microservice Demo", timestamp_generated: "RFC3339 timestamp of generation". Output only the JSON object content for the content parameter.
Make a write_file tool call with filename: "scenario_<id>/metadata.json" and the generated metadata JSON as content.
--- End Generation ---
